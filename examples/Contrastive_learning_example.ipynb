{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcddc2bf-d56a-43f6-abb8-0d1fd7473764",
   "metadata": {},
   "source": [
    "## Contrastive learning example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e416c153-cb34-4278-b4db-ba39b180590b",
   "metadata": {},
   "source": [
    "## Demo goal: species-level embeddings for ESKAPEe with curriculum + contrastive learning\n",
    "\n",
    "This notebook is a compact, end-to-end demo of **metric-learning style fine-tuning for genomic sequence embeddings**.\n",
    "\n",
    "We start from the ESKAPEE pathogen dataset, slice genomes/contigs into fixed-length segments, and fine-tune a ProkBERT encoder with a **CurricularFace-style classification head**. The key idea is to train in **cosine (angular) space**: embeddings and class prototypes are normalized, logits are scaled, and an angular margin is applied so the model is explicitly encouraged to build **tight within-class clusters** and **clear between-class separation**. The “curriculum” comes from the head itself, which progressively focuses training on harder examples as the representation improves.\n",
    "\n",
    "To make the effect tangible, we visualize embeddings with **UMAP** before and after a short training run. The goal is not to maximize accuracy in this toy setting, but to show how curricular metric learning reshapes the embedding space into something that is immediately useful for downstream tasks like clustering, retrieval, and lightweight classifiers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660368e3-f3ee-49d9-8847-19011795e9fa",
   "metadata": {},
   "source": [
    "## Setting Up the Environment\n",
    "\n",
    "While ProkBERT can operate on CPUs, leveraging GPUs significantly accelerates the process. Google Colab offers free GPU usage making it an ideal platform for trying and experimenting with ProkBERT models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec419eae-a713-4cbd-b2e1-d127f8ac2049",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/nbrg-ppcu/prokbert.git --quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97639921-f31e-4842-bde4-0bd779335980",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer, DataCollatorWithPadding\n",
    "from prokbert.sequtils import *\n",
    "from prokbert.training_utils import *\n",
    "from prokbert.models import ProkBertForCurricularClassification\n",
    "from prokbert.tokenizer import LCATokenizer\n",
    "from prokbert.curriculum_utils import compute_umap_for_dataset\n",
    "from datasets import Dataset, load_dataset, ClassLabel\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from os.path import join\n",
    "import os\n",
    "\n",
    "REPO_ID = \"neuralbioinfo/eskapee\"\n",
    "MODEL_NAME = \"neuralbioinfo/prokbert-mini-long\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1e46fe-1251-4e57-89b5-10f0b49867b6",
   "metadata": {},
   "source": [
    "### Enabling and testing the GPU (if you are using google colab)\n",
    "\n",
    "First, you'll need to enable GPUs for the notebook:\n",
    "\n",
    "- Navigate to Edit→Notebook Settings\n",
    "- select GPU from the Hardware Accelerator drop-down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d73495-b9b8-4381-80e0-e8f237dae971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if CUDA (GPU support) is available\n",
    "if not torch.cuda.is_available():\n",
    "    raise SystemError('GPU device not found')\n",
    "else:\n",
    "    device_name = torch.cuda.get_device_name(0)\n",
    "    print(f'Found GPU at: {device_name}')\n",
    "num_cores = os.cpu_count()\n",
    "print(f'Number of available CPU cores: {num_cores}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2794c0ca-0322-466b-a76e-cc2a21507a41",
   "metadata": {},
   "source": [
    "## Prepearing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e832eb-be7d-4dc1-be91-5afccc3596a4",
   "metadata": {},
   "source": [
    "### Load the dataset + encode `assembly` as a numeric label\n",
    "\n",
    "In this cell we pull `neuralbioinfo/eskapee` from the Hugging Face Hub and make the **assembly accession** a clean training label.\n",
    "\n",
    "What we do:\n",
    "- download the dataset (`split=\"train\"`)\n",
    "- create `label_id` by class-encoding `assembly` (integer IDs, stable mapping)\n",
    "- keep the original `assembly` string around for readability and plotting\n",
    "- print a quick top-10 label count table to confirm everything looks sensible\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d3ed7b-b937-42e8-bf33-b34eb5c3308a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Load dataset\n",
    "ds = load_dataset(REPO_ID, split=\"train\")\n",
    "\n",
    "ds = ds.add_column(\"assembly_label\", ds[\"assembly\"])\n",
    "ds = ds.class_encode_column(\"assembly_label\")          # now `assembly_label` is an integer-backed ClassLabel\n",
    "ds = ds.rename_column(\"assembly_label\", \"label_id\")    # trainer-friendly name\n",
    "\n",
    "# 4) Extract mappings (id2label / label2id)\n",
    "label_feature = ds.features[\"label_id\"]\n",
    "id2label = dict(enumerate(label_feature.names))\n",
    "label2id = {name: i for i, name in id2label.items()}\n",
    "\n",
    "print(f\"Number of assembly labels: {len(id2label)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb260c4-d85f-4e88-94fa-3e595fa5f6c0",
   "metadata": {},
   "source": [
    "## In this section we are going to perform the segmentation and the basic dataset preprocessing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bd3f7e-74a4-4ee5-b9cd-e5961c8ca026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the dataset into a pandas dataframe for further dataprocessing\n",
    "seed = 42\n",
    "test_size = 0.10\n",
    "\n",
    "sequences = ds.to_pandas()\n",
    "max_length = 512\n",
    "lut_cols = [\"sequence_id\", \"label_id\"]\n",
    "\n",
    "\n",
    "print(\"[prepare_dataset] Running segmentation\")\n",
    "segmentation_params = {\n",
    "    \"max_length\": max_length,\n",
    "    \"min_length\": int(max_length * 0.5),\n",
    "    \"type\": \"contiguous\",\n",
    "}\n",
    "raw_segment_df = segment_sequences(\n",
    "    sequences, segmentation_params, AsDataFrame=True\n",
    ")\n",
    "print(f\"[prepare_dataset] Number of segments: {len(raw_segment_df)}\")\n",
    "\n",
    "\n",
    "for extra in [\"assembly\", \"taxon\", \"taxon_short\", \"taxon_name\"]:\n",
    "    if extra in sequences.columns and extra not in lut_cols:\n",
    "        lut_cols.append(extra)\n",
    "        \n",
    "label_lut = sequences[lut_cols].drop_duplicates(subset=[\"sequence_id\"])\n",
    "if \"sequence_id\" not in raw_segment_df.columns:\n",
    "    raise ValueError(\n",
    "        f\"`raw_segment_df` has no `sequence_id` column. Available columns: {raw_segment_df.columns.tolist()}\"\n",
    "    )\n",
    "\n",
    "raw_segment_df = raw_segment_df.merge(\n",
    "    label_lut,\n",
    "    on=\"sequence_id\",\n",
    "    how=\"left\",\n",
    "    validate=\"many_to_one\",\n",
    ")\n",
    "raw_segment_df = raw_segment_df.sample(frac=1.0)\n",
    "raw_segment_df[\"label_id\"] = raw_segment_df[\"label_id\"].astype(\"int64\")\n",
    "hf_dataset = Dataset.from_pandas(raw_segment_df, preserve_index=False)\n",
    "hf_dataset = hf_dataset.rename_column(\"label_id\", \"labels\")\n",
    "\n",
    "split = hf_dataset.train_test_split(test_size=test_size, seed=seed, shuffle=True)\n",
    "train_ds = split[\"train\"]\n",
    "test_ds = split[\"test\"]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8964609d-f5b8-420f-b144-1933ef64234c",
   "metadata": {},
   "source": [
    "## Modell loading and definitions\n",
    "\n",
    "\n",
    "### What these curricular parameters do\n",
    "\n",
    "- `curricular_num_labels`  \n",
    "  How many classes you have (here: the number of assemblies you encoded). This sets the size of the class weight matrix used by the CurricularFace head.\n",
    "\n",
    "- `curricular_face_m` (margin)  \n",
    "  The **angular margin** applied to the target class in cosine space. Larger values enforce stricter separation between classes (can improve discrimination, but too large may make training unstable).\n",
    "\n",
    "- `curricular_face_s` (scale)  \n",
    "  A **logit scaling factor** for cosine similarities. Without scaling, cosine logits are small and gradients can be weak; `s` restores a useful gradient magnitude. Typical values are 16–64.\n",
    "\n",
    "- `classification_dropout_rate`  \n",
    "  Dropout applied in the classification stack to reduce overfitting.\n",
    "\n",
    "- `curriculum_hidden_size`  \n",
    "  The dimensionality used by the model’s embedding/projection feeding the CurricularFace head (often 128). This is the representation you typically visualize with UMAP and reuse for retrieval/clustering.\n",
    "\n",
    "- `id2label`, `label2id`  \n",
    "  Mappings for nice model metadata (readable labels in logs/outputs) and consistent class ordering.\n",
    "\n",
    "- `torch_dtype`  \n",
    "  Controls model weights dtype. Leave as default (`None`) unless you intentionally run fp16/bf16.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9578d122-c2cb-4d19-8269-905568d6585c",
   "metadata": {},
   "outputs": [],
   "source": [
    "curricular_face_m = 0.5          # angular margin (typical range ~0.2–0.6)\n",
    "curricular_face_s = 64.0         # logit scale (typical range ~16–64)\n",
    "classification_dropout_rate = 0.1\n",
    "curriculum_hidden_size = 128     # embedding/projection size used by the curricular head (often 128)\n",
    "\n",
    "use_bf16 = True\n",
    "model_dtype = torch.bfloat16 if use_bf16 else torch.float32\n",
    "\n",
    "\n",
    "model = ProkBertForCurricularClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    curricular_num_labels=len(id2label),\n",
    "    curricular_face_m=curricular_face_m,\n",
    "    curricular_face_s=curricular_face_s,\n",
    "    classification_dropout_rate=classification_dropout_rate,\n",
    "    curriculum_hidden_size=curriculum_hidden_size,\n",
    "    torch_dtype=model_dtype,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")\n",
    "\n",
    "tokenizer = LCATokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968f5ed6-4121-4f3f-a8e3-e23c57ea8fe6",
   "metadata": {},
   "source": [
    "\n",
    "# Now we can do the tokenization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661ea19b-2bfa-4854-9fe9-f1d4c0ce0a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cores = max(1, min(os.cpu_count() or 1, 16))  \n",
    "\n",
    "\n",
    "def _tokenize_fn(batch):\n",
    "    tok = tokenizer(\n",
    "        batch[\"segment\"],\n",
    "        padding=False,              \n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "    )\n",
    "    masks = tok[\"attention_mask\"]\n",
    "    # Keep labels (and any identifiers you want)\n",
    "    tok[\"labels\"] = batch[\"labels\"]\n",
    "    if \"sequence_id\" in batch:\n",
    "        tok[\"sequence_id\"] = batch[\"sequence_id\"]\n",
    "    if \"segment_id\" in batch:\n",
    "        tok[\"segment_id\"] = batch[\"segment_id\"]\n",
    "    return tok\n",
    "\n",
    "# Drop heavy text columns after tokenization, but keep identifiers + labels\n",
    "keep_cols = {\"labels\", \"sequence_id\", \"segment_id\"}\n",
    "remove_cols = [c for c in hf_dataset.column_names if c not in keep_cols and c != \"segment\"]\n",
    "\n",
    "print(f\"[prepare_dataset] Tokenizing with {num_cores} CPU core(s)\")\n",
    "tokenized_train_ds = train_ds.map(\n",
    "    _tokenize_fn,\n",
    "    batched=True,\n",
    "    num_proc=num_cores,\n",
    "    remove_columns=remove_cols + [\"segment\"],  # remove raw text segment post-tokenization\n",
    "    keep_in_memory=True,\n",
    "    desc=\"Tokenize segments\",\n",
    ")\n",
    "\n",
    "print(f\"[prepare_dataset] Tokenizing with {num_cores} CPU core(s)\")\n",
    "tokenized_test_ds = test_ds.map(\n",
    "    _tokenize_fn,\n",
    "    batched=True,\n",
    "    num_proc=num_cores,\n",
    "    remove_columns=remove_cols + [\"segment\"],  # remove raw text segment post-tokenization\n",
    "    keep_in_memory=True,\n",
    "    desc=\"Tokenize segments\",\n",
    ")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6550444e-bd89-44a9-8d01-3167d1e21c87",
   "metadata": {},
   "source": [
    "## Checking the embeddings before the training process\n",
    "\n",
    "Before we train anything, let’s sanity-check what the **pretrained** model already knows.\n",
    "\n",
    "In this cell we calculate a **UMAP projection** of a random sample of segment embeddings and color points by `taxon_short`. This gives us a quick visual readout of how the representation space is organized *out of the box*.\n",
    "\n",
    "Often you can already see that contigs/segments from different taxa are **reasonably well separated** even before fine-tuning. That baseline structure is useful: the training step that follows should mostly **tighten clusters** and improve separation for the specific labels we optimize (assemblies / taxa, depending on the setup).\n",
    "\n",
    "### UMAP: visualize a sample of segment embeddings (colored by taxon)\n",
    "\n",
    "Steps in this cell:\n",
    "- Sample up to **2,000** tokenized segments.\n",
    "- Compute embeddings and project them to **2D with UMAP**, keeping the **same row order** as the sampled dataset.\n",
    "- Join metadata (`assembly`, `taxon`, `taxon_short`, `taxon_name`) for labeling.\n",
    "- Plot a scatter where each dot is a segment embedding, **colored by `taxon_short`**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfa37cb-18a6-47b1-9b01-402b6a4907f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_n = 2000\n",
    "umap_seed = 123\n",
    "\n",
    "umap_ds = tokenized_test_ds.shuffle(seed=umap_seed).select(range(min(umap_n, len(tokenized_train_ds))))\n",
    "coords = compute_umap_for_dataset(\n",
    "    model=model,\n",
    "    dataset=umap_ds,\n",
    "    data_collator=data_collator,\n",
    "    batch_size=128,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "# coords are aligned with umap_ds order\n",
    "plot_df = pd.DataFrame(coords, columns=[\"umap_1\", \"umap_2\"])\n",
    "meta_cols = [\"sequence_id\", \"segment_id\", \"assembly\", \"taxon\", \"taxon_short\", \"taxon_name\"]\n",
    "meta_df = hf_dataset.select_columns(meta_cols).to_pandas()\n",
    "\n",
    "# Build plot dataframe in the same order as tokenized_test_ds_to_plot\n",
    "plot_df = pd.DataFrame(coords, columns=[\"umap_1\", \"umap_2\"])\n",
    "plot_df[\"sequence_id\"] = umap_ds[\"sequence_id\"]\n",
    "plot_df[\"segment_id\"]  = umap_ds[\"segment_id\"]\n",
    "plot_df[\"label_id\"]    = umap_ds[\"labels\"]\n",
    "\n",
    "# Join metadata (many-to-one should hold per segment_id; if not, switch to validate=\"many_to_many\")\n",
    "plot_df = plot_df.merge(\n",
    "    meta_df,\n",
    "    on=[\"sequence_id\", \"segment_id\"],\n",
    "    how=\"left\",\n",
    "    validate=\"one_to_one\",\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(12, 7))\n",
    "ax = sns.scatterplot(\n",
    "    data=plot_df,\n",
    "    x=\"umap_1\",\n",
    "    y=\"umap_2\",\n",
    "    hue=\"taxon_short\",\n",
    "    s=28,          # larger dots\n",
    "    alpha=0.85,\n",
    "    linewidth=0,\n",
    "    palette=\"tab20\",\n",
    ")\n",
    "\n",
    "ax.set_title(\"UMAP of ProkBERT embeddings (colored by taxa)\", pad=12)\n",
    "ax.set_xlabel(\"UMAP-1\")\n",
    "ax.set_ylabel(\"UMAP-2\")\n",
    "\n",
    "sns.move_legend(ax, \"upper left\", bbox_to_anchor=(1.02, 1), title=\"taxon_short\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54991a84-62de-4a2f-b8e6-1ef086a46982",
   "metadata": {},
   "source": [
    "## Training \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6f4477-e2df-4bc9-95a6-c417e0031347",
   "metadata": {},
   "source": [
    "### Training setup: two learning rates (backbone vs. curricular head)\n",
    "\n",
    "In this cell we run a short fine-tuning job using the Hugging Face `Trainer`, with one practical twist: we use **different learning rates** for the pretrained encoder and for the new classification head.\n",
    "\n",
    "- **Batch sizes / epochs**  \n",
    "  We train with `train_batch_size=64` for `num_train_epochs=0.5`. This is intentionally small—just enough to see the embedding space move in the next UMAP plot.\n",
    "\n",
    "- **Two parameter groups**  \n",
    "  We split parameters into:\n",
    "  - **Backbone** (`bert.*`): the pretrained ProkBERT encoder, updated gently with `backbone_lr=1e-5`\n",
    "  - **Head** (everything else): the curricular classification components, trained faster with `head_lr=5e-4`\n",
    "\n",
    "  This is a common fine-tuning pattern: keep the foundation model stable while letting the task-specific layers adapt quickly.\n",
    "\n",
    "- **Trainer configuration**  \n",
    "  `TrainingArguments` controls logging cadence, output directory, and precision (`bf16` is off here).  \n",
    "  We pass a custom optimizer (with the two LR groups) via `optimizers=(optimizer, None)` and compute accuracy on the eval split.\n",
    "\n",
    "After this finishes, we’ll re-run the UMAP embedding visualization to see how training reshaped the representation space.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae0387d-f455-4a85-93b3-ee1cfc2dafa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 64\n",
    "eval_batch_size = 64\n",
    "num_train_epochs = 0.5\n",
    "\n",
    "backbone_lr = 1e-5\n",
    "head_lr = 5e-4\n",
    "use_bf16 = False\n",
    "\n",
    "backbone_params = [p for n, p in model.named_parameters() if n.startswith(\"bert.\")]\n",
    "head_params = [p for n, p in model.named_parameters() if not n.startswith(\"bert.\")]\n",
    "\n",
    "optimizer = AdamW(\n",
    "    [\n",
    "        {\"params\": backbone_params, \"lr\": backbone_lr},\n",
    "        {\"params\": head_params, \"lr\": head_lr},\n",
    "    ],\n",
    ")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "        output_dir='eskapee_example',\n",
    "        overwrite_output_dir=False,\n",
    "        report_to=\"none\",\n",
    "        logging_steps=20,\n",
    "        per_device_train_batch_size=train_batch_size,\n",
    "        per_device_eval_batch_size=eval_batch_size,\n",
    "        num_train_epochs=num_train_epochs,\n",
    "        bf16=use_bf16,\n",
    "    )\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_ds,\n",
    "    eval_dataset=tokenized_test_ds,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    optimizers=(optimizer, None),\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93d0357-cf98-4e32-abe9-a59337543365",
   "metadata": {},
   "source": [
    "## Final visualization\n",
    "\n",
    "Now we repeat the exact same UMAP workflow **after training**. We reuse the same sampled dataset (`umap_ds`) and the same projection settings so the “before vs. after” comparison is meaningful.\n",
    "\n",
    "What happens in this cell:\n",
    "- We recompute embeddings with the **fine-tuned** model and project them to 2D with UMAP.\n",
    "- We join back the original metadata (`assembly`, `taxon`, `taxon_short`, `taxon_name`) so we can color points by `taxon_short`.\n",
    "- We plot the scatter again, using the same styling as before.\n",
    "\n",
    "What to look for:\n",
    "- Compared to the pretrained baseline, you should typically see **tighter within-class clusters** and **clearer separation between taxa**.\n",
    "- In this run, classes such as *Klebsiella* and *Escherichia* that previously sat closer together become **more cleanly separated**, while points within each taxon tend to cluster more tightly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6177f0f2-569b-4424-88fe-a37ea43c4f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = compute_umap_for_dataset(\n",
    "    model=model,\n",
    "    dataset=umap_ds,\n",
    "    data_collator=data_collator,\n",
    "    batch_size=128,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "# coords are aligned with umap_ds order\n",
    "plot_df = pd.DataFrame(coords, columns=[\"umap_1\", \"umap_2\"])\n",
    "\n",
    "meta_cols = [\"sequence_id\", \"segment_id\", \"assembly\", \"taxon\", \"taxon_short\", \"taxon_name\"]\n",
    "meta_df = hf_dataset.select_columns(meta_cols).to_pandas()\n",
    "\n",
    "# Build plot dataframe in the same order as tokenized_test_ds_to_plot\n",
    "plot_df = pd.DataFrame(coords, columns=[\"umap_1\", \"umap_2\"])\n",
    "plot_df[\"sequence_id\"] = umap_ds[\"sequence_id\"]\n",
    "plot_df[\"segment_id\"]  = umap_ds[\"segment_id\"]\n",
    "plot_df[\"label_id\"]    = umap_ds[\"labels\"]\n",
    "\n",
    "# Join metadata (many-to-one should hold per segment_id; if not, switch to validate=\"many_to_many\")\n",
    "plot_df = plot_df.merge(\n",
    "    meta_df,\n",
    "    on=[\"sequence_id\", \"segment_id\"],\n",
    "    how=\"left\",\n",
    "    validate=\"one_to_one\",\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(12, 7))\n",
    "ax = sns.scatterplot(\n",
    "    data=plot_df,\n",
    "    x=\"umap_1\",\n",
    "    y=\"umap_2\",\n",
    "    hue=\"taxon_short\",\n",
    "    s=28,          # larger dots\n",
    "    alpha=0.85,\n",
    "    linewidth=0,\n",
    "    palette=\"tab20\",\n",
    ")\n",
    "\n",
    "ax.set_title(\"UMAP of ProkBERT embeddings (colored by taxa)\", pad=12)\n",
    "ax.set_xlabel(\"UMAP-1\")\n",
    "ax.set_ylabel(\"UMAP-2\")\n",
    "\n",
    "sns.move_legend(ax, \"upper left\", bbox_to_anchor=(1.02, 1), title=\"taxon_short\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed2b083-c489-4f50-a5d6-8df4faf1a7da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
